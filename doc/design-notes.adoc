= Design Notes
:toc:

== 2021-Jan

After playing with my December experiment, I decided to take an alternate approach.
I no longer use macros to parse and run tests at test runtime.
I instead convert REPL assertions to deftest assertions a test generation time.

The disadvantage is that the generated tests look less like the original doc code blocks.

Advantages are:

1. I can freely bring in useful dependencies to help with the test generation.
So far I am experimenting with clojure.tools.reader and rewrite-cljc.
2. The generated tests look like normal clojure tests and can be easily reasoned about without studying a custom macros.

Other changes:

* I was prefixing generated test namespaces with `test-doc-blocks.gen`.
The idea was to provide isolation from other code.
Since the test-ns is under the control of the author (with the default being based on the doc filename), this perhaps presumptuous.
* I had some primitive support for bringing up inline ``require``s into the ns declaration (to support ClojureScript).
It is still primitive, but now I also support bringing up inline ``import``s into the ns declaration.
And do some recognizing of these elements when they, or parts of their bodies are wrapped in reader conditionals.
* Although I liked having one `deftest` with multiple ``testing``s, because it made for good looking test reports,
I decided to only have one `testing` per `deftest`.
This will allow for tagging of individual code blocks with metadata, which can then in turn be used by test runners.

Still to ponder:

* I'm fine with test generation including whatever deps make sense.
But I'd like test runtime to be truly free of any imposed deps including test-doc-blocks.
I have one macro remaining.
Perhaps I'll just copy of this ns at test generation time.
* Add metadata feature I mentioned above
* Allow a code block to target .clj or .cljs, currently only spitting to .cljc.

== 2020-Dec

=== Initial Thoughts
Heavily based on, and code used from, @seancorfield's https://github.com/seancorfield/readme[readme].

Sean's solution is an all-in-one.
Tests are generated run, then deleted.
Since I am supporting cljs in addition to clj, I think I'm going to separate generate from test.
This is less convenient, but also lets you use your test runner of choice.

Sean's readme project supports REPL and edit style code blocks.
I'll add support for more editor style code blocks and add some syntax for verifying stdout.
See examples docs for examples.

Some test blocks might have conflicting `(require ...)` with other test blocks in the same document.
I'll allow for test blocks to be isolated to their own test namespace.

To support ClojureScript, I'll need to merge the `(require ...)` into the generated test `(ns .. (:require ...))`.
Reasoning: ClojureScript inline `(require ...)` are REPL only - as far as I understand.

Sean makes use of a macro to convert extracted code blocks to tests at runtime.
I find this very interesting.

I considered, that instead of using a macro like Sean does, to rewrite code blocks to tests using rewrite-cljc at generation time.
I decided against this because I like minimizing deps for a test tool.
One could argue that bringing in extra deps for generation only and not for testing is ok, but I want to leave the door open for those who might want to merge these two steps.
So I'll stick with Sean's macro technique for now.

I'll make use of `(testing ...)` macro for descriptive tests that show file, maybe last section header and line number.
Opting to group all `testing` blocks under a single `deftest` has the advantage of cleaner output when running tests in a verbose mode, but also has the disadvantage of finding compilation errors originating from code blocks.
Clojure will report the error at the `deftest` line rather than the `testing` line.

Writing macros that work for Clojure and ClojureScript is a bit of a challenge, but mostly due to my learning curve, rather than any technical limitations.

Running code blocks can be a potentially dangerous thing.
For a contrived example, an author might provide a code snippit to illustrate how to delete all files on your system.
So, although it might be convenient, I'll try to force caution by:

1. only processing files explicitly listed.
2. by default, only generate tests for code blocks that have been tagged to be processed.
This can be overriden with an invocation option such as `{:test :all}`, maybe the default will be `:tagged-only`.
Or maybe this is too much? Yeah, the user has listed the file, that's good enough.
We'll add a big warning in the README.

Continueing with safety, we'll be generating potentially more than one file.
To avoid accidental deletion of other files, we'll

1. fail on soft links in deletion set
2. always create the same root dir under a specified target dir and delete recursively from there.

I'll start with support for asciidoctor, because this what I write my documents in, but will likely quickly move to also supporting CommonMark.

Generated tests will take advantage of `(testing ...)` to provide a rich descriptive string for the code block under test.
The string might contain:

* filename
* last section header before code block
* line number

Options will be optionally conveyed via comments in docs.
We'll take inspiration for clj-kondo for syntax.

* In Asciidoctor this will look like: `// {:test-doc-blocks/my-option x}`
* In CommonMark: `\<-- {:test-doc-blocks/my-option x} -\->`

I could bring in full featured parsers for Asciidoctor and CommonMark but this would mean extra unwanted deps.
I'll instead implement simple parsing that should be good enough in most cases.

=== Feedback from community

I asked some folks about any existing conventions for what I sketched as `=stdout=>` and got back some great responses:

@sogaiu

* one thing to consider might be whether you want to be able to distinguish between return values and output.
it wasn't clear to me from the snippets above how that might occur.
* another consideration might be if you want to verify stdout vs stderr (though arranging for this might be tricky depending on how things are done underneath?).
with your sketch, perhaps you'd use "=stderr=>" as a prefix?
* i was also interested in verying output but didn't set anything down.
in my case i've tried to make the notation concise with the idea that this stuff might be entered manually.
thus i've steered clear of longer things if possible.
* on a related note, i took a quick peek at test-doc-blocks,
but didn't find anything about supporting expected return values that might be more nicely formatted across lines.
in alc.x-as-tests' case, i used #_ to prefix multiline constructs: https://github.com/sogaiu/alc.x-as-tests/blob/master/doc/comment-block-tests.md (search for "discard")

@uochan

* FWIW, I also have a similar library to test codes in docstring mainly.
But it is also usable for external documents like markdown or asciidoc.
https://github.com/liquidz/testdoc

@dominicm

* Vim fireplace prefixes lines with `;{sp}` for stdout

@pez

* We have a similar problem in the Calva output window.
So far only prefixing both stdout and stderr with `;{sp}`.
But I have been wanting to start using maybe `;o{sp}` and `;e{sp}`.

We then dug into clearly representing eval vs stdout and stderr a bit.

Other

* One person kindly warned me privately this project might be a bit of a rabbit hole.
I see their point, but my main customer is rewrite-cljc, and it already found issues there, so I'll carry on.

=== Ideas for later

* Support code snippits that include `(requires ...)` under reader conditionals.

* Currently generating tests to cljc. Ever any need for .cls or .clj?

* Could include gen test delete workflow like Sean does. Maybe?
